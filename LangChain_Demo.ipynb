{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a pefume with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "notes = \"floral, citrus, musk\"\n",
    "chain.invoke(notes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1: give notes a name\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a pefume with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "# Chain 1: input = notes, output = perfume name\n",
    "chain1 = LLMChain(llm=llm, prompt=first_prompt, output_key=\"perfume_name\")\n",
    "# prompt template 2: give name a description\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 word description for a perfume with the following name: {perfume_name}\",\n",
    ")\n",
    "\n",
    "# Chain 2: input = perfume name, output = perfume description\n",
    "chain2 = LLMChain(llm=llm, prompt=second_prompt, output_key=\"perfume_description\")\n",
    "#prompt template 3: convert the description to a tagline\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a catchy 8 word tagline for a perfume with the following description: {perfume_description}\",\n",
    ")\n",
    "\n",
    "# Chain 3: input = perfume description, output = perfume tagline\n",
    "chain3 = LLMChain(llm=llm, prompt=third_prompt, output_key=\"perfume_tagline\")\n",
    "# prompt template 4: similar fragrance to notes\n",
    "fifth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"List 3 other perfumes with the following notes: {notes}\",\n",
    ")\n",
    "\n",
    "# Chain 4: input = notes, output = similar fragrances\n",
    "chain4 = LLMChain(llm=llm, prompt=fifth_prompt, output_key=\"similar_fragrances\")\n",
    "# overall chain: input= notes\n",
    "# and output = perfume name, description, tagline, similar fragrances\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3, chain4],\n",
    "    input_variables=[\"notes\"],\n",
    "    output_variables=[\"perfume_name\", \"perfume_description\", \"perfume_tagline\", \"similar_fragrances\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "overall_chain(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A with custom data & RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings # chat completion model and embeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter # split text into characters\n",
    "from langchain.document_loaders import CSVLoader # load data from a csv file - from langchain_community\n",
    "from langchain.vectorstores import DocArrayInMemorySearch #vectorstore, in memory, no need to connect to an external vectorestore\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document loader - each doc represents a perfume\n",
    "documents = 'data/final_perfume_data.csv'\n",
    "loader = CSVLoader(file_path=documents, encoding='unicode_escape').load()\n",
    "\n",
    "# split text into characters\n",
    "\n",
    "\n",
    "# create embeddings\n",
    "\n",
    "\n",
    "# example of whta the embeddings look like\n",
    "embed = embeddings.embed_query(\"floral, citrus, musk\")\n",
    "print(len(embed)) #print the length of the example embedding\n",
    "print(embed[:5]) #print first few vectors\n",
    "\n",
    "# create vectorstore\n",
    "vectorstore_db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search\n",
    "\n",
    "query = \"please list similar fragrances to chanel no 5.\"\n",
    "docs = vectorstore_db.similarity_search(query)\n",
    "\n",
    "results = \"\".join([docs[i].page_content for i in range(len(docs))])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# create retriever\n",
    "\n",
    "\n",
    "# create a chat model\n",
    "\n",
    "\n",
    "# join docs in a variable\n",
    "qdocs = \"\\n\\n\".join([docs[i].page_content for i in range(len(docs))])\n",
    "\n",
    "\n",
    "# create a prompt template\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return the answer in a markdown table with the name, brand and image.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "# create a custom prompt\n",
    "\n",
    "\n",
    "# display the response\n",
    "def display_markdown(content):\n",
    "    display(Markdown(content))\n",
    "    return content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\"context\":  | , \"question\": RunnablePassthrough()}\n",
    "    | \n",
    "    | \n",
    "    | StrOutputParser() #converts chat message to a string\n",
    "    | display_markdown\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"What are 4 similar fragrances to Chanel No 5?\")\n",
    "# rag_chain.invoke(\"What are 4 similar fragrances to Vanille Coco?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
